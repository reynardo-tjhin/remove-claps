{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "\n",
    "```\n",
    "Cepstrum    Quefrency   Liftering   Rhamonic\n",
    "   /\\          /\\          /\\          /\\\n",
    "   ||          ||          ||          ||\n",
    "   \\/          \\/          \\/          \\/\n",
    "Spectrum    Frequency   Filtering   Harmonic\n",
    "```\n",
    "\n",
    "#### A Historical Note on Cepstrum\n",
    "\n",
    "- Developed while studying echoes in seismic signals (1960s)\n",
    "- Audio feature of choice for speech recognition / identification (1970s)\n",
    "- Music processing (2000s)\n",
    "\n",
    "### Computing the cepstrum\n",
    "\n",
    "```\n",
    "C(x(t)) = F^-1 [ log( F(x(t)) ) ]\n",
    "```\n",
    "1. Apply the Fourier Transform on the discrete signal\n",
    "2. Apply the logarithmic scale on the result of 1\n",
    "3. Apply the Inverse Fourier Transform on the result of 2\n",
    "\n",
    "\n",
    "### Understanding the cepstrum\n",
    "\n",
    "![Understanding the Cepstrum](./images/Understanding%20the%20Cepstrum.png)\n",
    "\n",
    "### Speech\n",
    "\n",
    "Speech = Convolution of vocal tract frequency response with glottal pulse\n",
    "\n",
    "### Formalising Speech\n",
    "\n",
    "![Formalising Speech](./images/Formalising%20Speech.png)\n",
    "\n",
    "![Formalising Speech with Graphs](./images/Formalising%20Speech%20(with%20Graphs).png)\n",
    "\n",
    "The Goal is to **separate the components**: from speech to the vocal tract frequency response and glottal pulse.\n",
    "However, the glottal pulse is not very important.\n",
    "\n",
    "![Separating Components](./images/Separating%20Components.png)\n",
    "\n",
    "**The yellow circle is the lower frequency (4 Hz) and the purple-pinkish is the higher frequency (100 Hz).\n",
    "\n",
    "To remove the glottal pulse, we use a way called **liftering** (filtering).\n",
    "\n",
    "![Liftering](./images/Liftering.png)\n",
    "\n",
    "### Computing Mel-Frequency Cepstral Coefficients\n",
    "\n",
    "![Computing Mel-Frequency Cepstral Coefficients](./images/Computing%20Mel-Frequency%20Cepstral%20Coefficients.png)\n",
    "\n",
    "However, instead of using Inverse DFT, we use Discrete Cosine Transform because\n",
    "- Simplified version of Fourier Transform\n",
    "- Get real-valued coefficient\n",
    "- Decorrelate energy in different mel bands\n",
    "- Reduce the number of dimensions to represent spectrum (sort of like dimensionality reduction)\n",
    "\n",
    "### How many Coefficients?\n",
    "\n",
    "- Traditionally: first 12 - 13 coefficients\n",
    "- First coefficients keep most information (e.g. formants, spectral envelope)\n",
    "- Use △ and △△ MFCCs\n",
    "- Total 39 coefficients per frame\n",
    "\n",
    "### Visualising MFCCs\n",
    "\n",
    "![Visualising MFCCs](./images/Visiualising%20MFCCs.png)\n",
    "\n",
    "### MFCCs Advantages and Disadvantages\n",
    "\n",
    "Advantages:\n",
    "- Describe the \"large\" structures of the spectrum\n",
    "- Ignore fine spectral structures\n",
    "- Work well in speech and music processing\n",
    "\n",
    "Disadvantages:\n",
    "- Not robust to noise\n",
    "- Extensive knowledge engineering\n",
    "- Not efficient for synthesis\n",
    "\n",
    "### MFCCs Applications\n",
    "\n",
    "- Speech processing\n",
    "   - Speech recognition\n",
    "   - Speaker recognition\n",
    "   - etc...\n",
    "- Music processing\n",
    "   - Music genre classification\n",
    "   - Mood classification\n",
    "   - Automatic tagging\n",
    "   - etc...\n",
    "\n",
    "**With the rise in Deep Learning, Spectrogram and Mel Spectrogram are more popular nowadays than MFCCs.\n",
    "MFCCs were popular before deep learning."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
